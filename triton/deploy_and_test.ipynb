{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简化版triton模型部署与测试\n",
    "\n",
    "本笔记本演示如何部署一个简化版的基于PyTorch的模型到SageMaker上，该模型仅执行基本的torch张量操作，无需模型微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 配置sagemaker，获取 account id 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker boto3 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = 'arn:aws:iam::310850127430:role/service-role/AmazonSageMaker-ExecutionRole-20240425T101325'\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 构建和上传Docker镜像到ECR\n",
    "\n",
    "我们需要先构建Docker镜像并将其上传到ECR（Elastic Container Registry）。这里有两种方式：\n",
    "\n",
    "### 1.1 使用提供的脚本（推荐）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ACCOUNT=310850127430\n",
      "env: REGION=us-west-2\n",
      "310850127430.dkr.ecr.us-west-2.amazonaws.com/sagemaker-endpoint/whisper-triton-byoc:latest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/home/ubuntu/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      " => [internal] load build definition from Dockerfile.server                0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (1/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.server                0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 621B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:24.10-py3     0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (1/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.server                0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 621B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:24.10-py3     0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (2/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.server                0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 621B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/tritonserver:24.10-py3     0.4s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (11/11) FINISHED                               docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.server                0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 621B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/tritonserver:24.10-py3     0.4s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM nvcr.io/nvidia/tritonserver:24.10-py3@sha256:48f5247728bbc  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 63B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] RUN apt update && apt-get install -y ffmpeg               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] WORKDIR /workspace                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/6] COPY requirements.txt /workspace/requirements.txt         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/6] COPY serve /workspace/serve                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/6] RUN pip install --no-cache-dir --extra-index-url https:/  0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:6969ea200337465831967d0db4fba32cffa6739c62637  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/sagemaker-endpoint/whisper-triton-byoc:latest   0.0s\n",
      "\u001b[0m\u001b[?25hThe push refers to repository [310850127430.dkr.ecr.us-west-2.amazonaws.com/sagemaker-endpoint/whisper-triton-byoc]\n",
      "\n",
      "\u001b[1Be5ca68a3: Preparing \n",
      "\u001b[1B2e18ab6b: Preparing \n",
      "\u001b[1Bcf17ec4f: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B0645011e: Preparing \n",
      "\u001b[1B47013f5d: Preparing \n",
      "\u001b[4Bbf18a086: Preparing \n",
      "\u001b[5Bbf18a086: Preparing \n",
      "\u001b[6Bbf18a086: Preparing \n",
      "\u001b[1B3ca1bf2e: Preparing \n",
      "\u001b[1Bb104741a: Preparing \n",
      "\u001b[1Bb3b31578: Preparing \n",
      "\u001b[1B1ce166dd: Preparing \n",
      "\u001b[1B51d8983d: Preparing \n",
      "\u001b[1Bc6c233f7: Preparing \n",
      "\u001b[1B82fa150d: Preparing \n",
      "\u001b[1B47e518f5: Preparing \n",
      "\u001b[1B8a220a55: Preparing \n",
      "\u001b[1Be58addb3: Preparing \n",
      "\u001b[1B520db613: Preparing \n",
      "\u001b[1Bd6484379: Preparing \n",
      "\u001b[1B7e7743c0: Preparing \n",
      "\u001b[1B9ac10bb8: Preparing \n",
      "\u001b[1B727098a3: Preparing \n",
      "\u001b[1B746bdb5a: Preparing \n",
      "\u001b[23Bf18a086: Preparing \n",
      "\u001b[1B7749123e: Preparing \n",
      "\u001b[1Be0d81582: Layer already exists \u001b[28A\u001b[2K\u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[12A\u001b[2K\u001b[7A\u001b[2K\u001b[2A\u001b[2Klatest: digest: sha256:96380de14a15083affe98aa6399f51ff2fbcbf791428d7a7273d6197c8b22082 size: 7029\n"
     ]
    }
   ],
   "source": [
    "# 设置环境变量\n",
    "%env ACCOUNT={account_id}\n",
    "%env REGION={region}\n",
    "\n",
    "# 使用build_and_push.sh脚本构建并上传镜像\n",
    "!chmod +x ./build_and_push.sh\n",
    "!./build_and_push.sh sagemaker-endpoint/whisper-triton-byoc:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 手动构建和上传（步骤详解）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 定义镜像名称和ECR仓库\n",
    "# DOCKER_IMAGE = \"sagemaker-endpoint/whisper-triton-byoc:latest\"\n",
    "# REPO_NAMESPACE = \"sagemaker-endpoint/whisper-triton-byoc\"\n",
    "# TAG = \"latest\"\n",
    "\n",
    "# # 2. 创建ECR仓库（如果不存在）\n",
    "# !aws ecr describe-repositories --repository-names \"{REPO_NAMESPACE}\" > /dev/null 2>&1 || \\\n",
    "# aws ecr create-repository --repository-name \"{REPO_NAMESPACE}\"\n",
    "\n",
    "# # 3. 登录到Docker\n",
    "# !aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\n",
    "\n",
    "# # 4. 构建Docker镜像\n",
    "# !docker build . -f Dockerfile.server -t {DOCKER_IMAGE}\n",
    "\n",
    "# # 5. 标记和推送镜像到ECR\n",
    "# REPO_NAME = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{REPO_NAMESPACE}:{TAG}\"\n",
    "# !docker tag {DOCKER_IMAGE} {REPO_NAME}\n",
    "# !docker push {REPO_NAME}\n",
    "\n",
    "# # 设置CONTAINER变量用于后续步骤\n",
    "# CONTAINER = REPO_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备模型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# deploy_config.sh\n",
      "\n",
      "#注意 s3 路径最后加上 / \n",
      "S3_PATH=\"s3://a-web-uw2/test_triton/\"\n",
      "model_data/\n",
      "model_data/ssh_helper_start.py\n",
      "model_data/run_server.py\n",
      "model_data/model_repo_whisper_trtllm/\n",
      "model_data/model_repo_whisper_trtllm/whisper/\n",
      "model_data/model_repo_whisper_trtllm/whisper/config.pbtxt\n",
      "model_data/model_repo_whisper_trtllm/whisper/1/\n",
      "model_data/model_repo_whisper_trtllm/whisper/1/__pycache__/\n",
      "model_data/model_repo_whisper_trtllm/whisper/1/__pycache__/model.cpython-310.pyc\n",
      "model_data/model_repo_whisper_trtllm/whisper/1/model.py\n",
      "model_data/start_triton_and_client.sh\n",
      "model_data/download_model_from_s3.py\n",
      "model_data/deploy_config.sh\n",
      "model_data/whisper_api.py\n",
      "tar: The following options were used after non-option arguments.  These options are positional and affect only arguments that follow them.  Please, rearrange them properly.\n",
      "tar: --exclude ‘model_data/.ipynb_checkpoints’ has no effect\n",
      "tar: --exclude ‘model_data/__pycache__’ has no effect\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-310850127430/whisper_deploy_codes/model_data.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 确保先删除之前的打包文件\n",
    "!rm -f model_data.tar.gz\n",
    "\n",
    "# 显示部署配置内容\n",
    "!cat model_data/deploy_config.sh\n",
    "\n",
    "# 打包模型数据\n",
    "!tar czvf model_data.tar.gz model_data/ --exclude=model_data/.ipynb_checkpoints --exclude=model_data/__pycache__\n",
    "\n",
    "# 上传到S3\n",
    "s3_code_prefix = f\"whisper_deploy_codes\"\n",
    "bucket = sess.default_bucket()\n",
    "code_artifact = sess.upload_data(\"model_data.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用 SSH-helper 进行调试（可选）\n",
    "\n",
    "Since we are using the BYOC (Bring Your Own Container) method to deploy model, we can deploy and debug the code using SSH Helper after preparing the initial code. Once the debugging is successful, we can then deploy it using the regular method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sagemaker_ssh_helper==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper\n",
    "CONTAINER='310850127430.dkr.ecr.us-west-2.amazonaws.com/sagemaker-endpoint/whisper-triton-byoc:latest'\n",
    "model = Model(image_uri=CONTAINER, model_data=code_artifact, role=role,dependencies=[SSHModelWrapper.dependency_dir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import Predictor\n",
    "\n",
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "# instance_type = \"ml.p4d.24xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"whisper-trt-triton-sshelper\")\n",
    "\n",
    "ssh_wrapper = SSHModelWrapper.create(model, connection_wait_time_seconds=0)  # <--NEW--\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-west-2:310850127430:endpoint/whisper-trt-triton-sshelper-2025-11-01-03-01-10-009\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "# 等待端点创建完成\n",
    "import time\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# aws ssm start-session --target <Your_instance_ids> \n",
    "instance_ids = ssh_wrapper.get_instance_ids(timeout_in_sec=0)\n",
    "print(instance_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 正式部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(\n",
    "#     model_data=code_artifact,\n",
    "#     image_uri=CONTAINER,\n",
    "#     role=role,\n",
    "# )\n",
    "\n",
    "# # 部署模型到endpoint\n",
    "# endpoint_name = sagemaker.utils.name_from_base(\"simplified-whisper-torch-model\")\n",
    "# print(f\"endpoint_name: {endpoint_name}\")\n",
    "# predictor = model.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.g5.4xlarge',\n",
    "#     endpoint_name=endpoint_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 推理调用测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/ubuntu/.venv/lib/python3.12/site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.12/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# endpoint_name = 'whisper-trt-triton-sshelper-2025-10-30-09-52-49-729'\n",
    "endpoint_name = endpoint_name\n",
    "def encode_audio(audio_file_path):\n",
    "    # 加载音频文件\n",
    "    audio = AudioSegment.from_wav(audio_file_path)\n",
    "    \n",
    "    # 检查是否为双通道\n",
    "    if audio.channels == 2:\n",
    "        print(\"检测到双通道音频，正在转换为单通道...\")\n",
    "        # 将双通道转换为单通道\n",
    "        audio = audio.set_channels(1)\n",
    "    \n",
    "    # 将音频数据写入内存缓冲区\n",
    "    buffer = io.BytesIO()\n",
    "    audio.export(buffer, format=\"wav\")\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # 将缓冲区的内容编码为 base64\n",
    "    return base64.b64encode(buffer.read()).decode('utf-8')\n",
    "\n",
    "def invoke_sagemaker_endpoint(runtime_client, endpoint_name, audio_data, repetition_penalty=1.0, whisper_prompt=\"\"):\n",
    "    \"\"\"Invoke SageMaker endpoint with audio data\"\"\"\n",
    "    payload = {\n",
    "        \"whisper_prompt\": whisper_prompt,\n",
    "        \"audio_data\": audio_data,\n",
    "        \"repetition_penalty\": repetition_penalty\n",
    "    }\n",
    "    \n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    return result\n",
    "\n",
    "def process_audio(audio_path, endpoint_name, whisper_prompt=\"\"):\n",
    "    # Read and encode the audio file\n",
    "    print(\"Reading and encoding audio file...\")\n",
    "    audio_data = encode_audio(audio_path)\n",
    "\n",
    "    # Create a SageMaker runtime client\n",
    "    runtime_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "    # Invoke the SageMaker endpoint\n",
    "    print(f\"Invoking SageMaker endpoint: {endpoint_name}\")\n",
    "    result = invoke_sagemaker_endpoint(\n",
    "        runtime_client,\n",
    "        endpoint_name,\n",
    "        audio_data,\n",
    "        repetition_penalty=1.0,\n",
    "        whisper_prompt=whisper_prompt\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy audio file at ./audio.wav\n"
     ]
    }
   ],
   "source": [
    "# 创建测试音频文件\n",
    "def create_dummy_audio(output_path=\"audio.wav\", duration=3.0, sample_rate=16000):\n",
    "    \"\"\"Create a dummy audio file for testing.\"\"\"\n",
    "    import numpy as np\n",
    "    import soundfile as sf\n",
    "    \n",
    "    # Generate some random data (white noise)\n",
    "    samples = np.random.uniform(-0.1, 0.1, size=int(duration * sample_rate))\n",
    "    # Add a simple sine wave to make it more interesting\n",
    "    t = np.linspace(0, duration, int(duration * sample_rate), False)\n",
    "    sine = 0.3 * np.sin(2 * np.pi * 440 * t)  # 440 Hz sine wave\n",
    "    samples = samples + sine\n",
    "    \n",
    "    # Normalize\n",
    "    samples = samples / np.max(np.abs(samples))\n",
    "    \n",
    "    # Save as WAV file\n",
    "    sf.write(output_path, samples, sample_rate)\n",
    "    print(f\"Created dummy audio file at {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# 创建测试音频文件\n",
    "audio_path = create_dummy_audio(\"./audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and encoding audio file...\n",
      "Invoking SageMaker endpoint: whisper-trt-triton-sshelper-2025-11-01-03-01-10-009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing result:\n",
      "{'code': 0, 'message': 'Success', 'transcribe_text': \"Transcription (TEXT_PREFIX: '', WAV shape: (1, 240000), rep_penalty: 1.0)\"}\n",
      "CPU times: user 47 ms, sys: 1.14 ms, total: 48.1 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "audio_path = \"./audio.wav\"\n",
    "endpoint_name = endpoint_name\n",
    "whisper_prompt = \"\"  # Optional: add a prompt if needed\n",
    "\n",
    "# Call the function\n",
    "result = process_audio(audio_path, endpoint_name, whisper_prompt)\n",
    "\n",
    "# Print the result\n",
    "print(\"Processing result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 清理资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources cleaned up.\n"
     ]
    }
   ],
   "source": [
    "# 删除端点和模型，避免额外费用\n",
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "sess.delete_model(model.name)\n",
    "print(\"Resources cleaned up.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
